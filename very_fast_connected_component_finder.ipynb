{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connected_components(sc, edges, n_dist = 5):\n",
    "    \n",
    "    def cc_find_root(group, found_new_pair):\n",
    "        node, values = group\n",
    "        \n",
    "        #find the smalled vertex id in the current adjecency list \n",
    "        smallest = min(values  + [node])\n",
    "        \n",
    "        \n",
    "        emit = []\n",
    "        #if smallest is not the node \n",
    "        #emit the pairs with smallest for each node in the group\n",
    "        if smallest < node:\n",
    "            emit.append((node, smallest))\n",
    "            for vi in values:\n",
    "                if vi != smallest:\n",
    "                    emit.append((vi, smallest))\n",
    "                    found_new_pair.add(1)\n",
    "        return emit\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        edges.persist()\n",
    "        found_new_pair = sc.accumulator(0)\n",
    "        print (\"JOB_LOG\", \"  ITERATION : \",n_dist )\n",
    "        \n",
    "        #ccf map\n",
    "        s1 = edges.flatMap(lambda x : [(x[0], x[1]), (x[1], x[0])])\n",
    "        #s1.take(1)\n",
    "        \n",
    "        #ccf reduce\n",
    "        s2 = s1.groupByKey().map(lambda (x,y): (x, list(y)))\n",
    "        #print s2.take(1)\n",
    "        \n",
    "        s3 = s2.flatMap(lambda x : cc_find_root(x, found_new_pair))\n",
    "        s3.cache()\n",
    "        print \"JOB_LOG\",\"total relations count:\", s3.count() #necessary to perform action else accumulator will not update\n",
    "        \n",
    "        \n",
    "        #ccf deduce\n",
    "        edges.unpersist()\n",
    "        edges = s3.distinct() \n",
    "        \n",
    "        print \"JOB_LOG\",\"New pairs found :\",found_new_pair.value\n",
    "        if found_new_pair.value == 0 or n_dist == 0:\n",
    "            break\n",
    "        n_dist -= 1\n",
    "    \n",
    "    return edges.map(lambda x: (x[1], x[0])).groupByKey().map(lambda (x,y) : (x, list(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "ss = SparkSession.builder.config(\"spark.sql.hive.verifyPartitionPath\",\n",
    "                                     \"false\").enableHiveSupport().getOrCreate()\n",
    "sc = ss.sparkContext\n",
    "sqlContext =  SQLContext(sc)\n",
    "\n",
    "edges = sc.parallelize([(\"a\",\"b\"),\n",
    "                       (\"b\", \"c\"),\n",
    "                       (\"d\", \"e\"),\n",
    "                       (\"d\", \"f\"),\n",
    "                       (\"g\", \"b\")\n",
    "                       ])\n",
    "res = find_connected_components(sc, edges)\n",
    "res.take(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
